# -*- coding: utf-8 -*-
"""NLP_Workshop.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tJldkxK_uPcnwpnyhj3p36IVswPIndX3

# Classifying Movie Reviews with the Naive Bayes Classifier

Data Folder
https://drive.google.com/drive/folders/1EgHwqsjgA-dhYGFUKx8rWxIa9htwsl9W?usp=sharing

1. Please add this folder to your drive and make a copy of it (please name the copy "data")
2. Click the folder icon on the far left side of the screen
3. Click on the folder icon with the drive logo on it to attach your drive to the runtime.
4. Go to your drive and locate the "data" folder that you just added
5. Hover over the folder, click on the three dots, and click on copy path.
6. Paste this filepath below and delete the "/data" at the end of the pasted filepath.
"""

# Commented out IPython magic to ensure Python compatibility.
# # navigate to the appropriate directory
# %cd /content/drive/Shareddrives/Aggie Data Science Club New/Workshops/NLP Workshop/NLP Easy # PASTE HERE

# #show the files in the current directory ("data" should be here!)
# !ls

import os
import math
from collections import defaultdict

class NaiveBayes:
  class TrainSplit:
    """Represents a set of training/testing data. self.train is a list of Examples, as is self.test.
    """
    def __init__(self):
      self.train = []
      self.test = []

  class Example:
    """Represents a document with a label. klass is 'pos' or 'neg' by convention.
       words is a list of strings.
    """
    def __init__(self):
      self.klass = ''
      self.words = []


  def __init__(self):
    """NaiveBayes initialization"""
    self.FILTER_STOP_WORDS = False
    self.BOOLEAN_NB = False
    self.stopList = set(self.readFile('data/english.stop'))
    self.numFolds = 10

    # the count of each class
    self.class_counts = defaultdict(int)
    # word frequencies per class
    self.word_counts = defaultdict(lambda: defaultdict(int))
    # set of all unique words
    self.vocabulary = set()
    # total number of documents
    self.total_docs = 0

  #############################################################################
  # TODO TODO TODO TODO TODO
  # Implement the Multinomial Naive Bayes classifier and the Naive Bayes Classifier with
  # Boolean (Binarized) features.
  # If the BOOLEAN_NB flag is true, your methods must implement Boolean (Binarized)
  # Naive Bayes (that relies on feature presence/absence) instead of the usual algorithm
  # that relies on feature counts.
  #
  #
  # If any one of the FILTER_STOP_WORDS and BOOLEAN_NB flags is on, the
  # other one is meant to be off.

  def classify(self, words):
    """ TODO
      'words' is a list of words to classify. Return 'pos' or 'neg' classification.
    """
    if self.FILTER_STOP_WORDS:
      words =  self.filterStopWords(words)

    if self.BOOLEAN_NB:
      words = set(words)

    log_probs = {}
    vocab_size = len(self.vocabulary)

    for klass in self.class_counts:
      log_probs[klass] = math.log(self.class_counts[klass] / self.total_docs)

      total_word_count = sum(self.word_counts[klass].values())

      for word in words:
          word_count = self.word_counts[klass][word]
          log_probs[klass] += math.log((word_count + 1) / (total_word_count + vocab_size))

    return max(log_probs, key=log_probs.get)


  def addExample(self, klass, words):
    """
     * TODO
     * Train your model on an example document with label klass ('pos' or 'neg') and
     * words, a list of strings.
     * You should store whatever data structures you use for your classifier
     * in the NaiveBayes class.
     * Returns nothing
    """
    if self.FILTER_STOP_WORDS:
      words = self.filterStopWords(words)

    self.class_counts[klass] += 1
    self.total_docs += 1

    if self.BOOLEAN_NB:
      words = set(words)

    for word in words:
      self.word_counts[klass][word] += 1
      self.vocabulary.add(word)

  # END TODO (Modify code beyond here with caution)
  #############################################################################


  def readFile(self, fileName):
    """
     * Code for reading a file.  you probably don't want to modify anything here,
     * unless you don't like the way we segment files.
    """
    print(f"reading file with the name{fileName}")
    contents = []
    f = open(fileName)
    for line in f:
      contents.append(line)
    f.close()
    result = ('\n'.join(contents)).split()
    return result

  def trainSplit(self, trainDir):
    """Takes in a trainDir, returns one TrainSplit with train set."""
    split = self.TrainSplit()
    posTrainFileNames = os.listdir('%s/pos/' % trainDir)
    negTrainFileNames = os.listdir('%s/neg/' % trainDir)
    for fileName in posTrainFileNames:
      example = self.Example()
      example.words = self.readFile('%s/pos/%s' % (trainDir, fileName))
      example.klass = 'pos'
      split.train.append(example)
    for fileName in negTrainFileNames:
      example = self.Example()
      example.words = self.readFile('%s/neg/%s' % (trainDir, fileName))
      example.klass = 'neg'
      split.train.append(example)
    return split

  def train(self, split):
    for example in split.train:
      words = example.words
      if self.FILTER_STOP_WORDS:
        words =  self.filterStopWords(words)
      self.addExample(example.klass, words)


  def crossValidationSplits(self, trainDir):
    """Returns a list of TrainSplits corresponding to the cross validation splits."""
    splits = []
    posTrainFileNames = os.listdir('%s/pos/' % trainDir)
    negTrainFileNames = os.listdir('%s/neg/' % trainDir)

    for fold in range(0, self.numFolds):
      split = self.TrainSplit()
      for fileName in posTrainFileNames:
        example = self.Example()
        example.words = self.readFile('%s/pos/%s' % (trainDir, fileName))
        example.klass = 'pos'
        if fileName[2] == str(fold):
          split.test.append(example)
        else:
          split.train.append(example)
      for fileName in negTrainFileNames:
        example = self.Example()
        example.words = self.readFile('%s/neg/%s' % (trainDir, fileName))
        example.klass = 'neg'
        if fileName[2] == str(fold):
          split.test.append(example)
        else:
          split.train.append(example)
      splits.append(split)
    return splits

  def filterStopWords(self, words):
    """Filters stop words."""
    filtered = []
    for word in words:
      if not word in self.stopList and word.strip() != '':
        filtered.append(word)
    return filtered

# def train(FILTER_STOP_WORDS, BOOLEAN_NB):
#     nb = NaiveBayes()
#     splits = nb.crossValidationSplits('data/imdb1')

#     for split in splits:
#         nb.FILTER_STOP_WORDS = FILTER_STOP_WORDS
#         nb.BOOLEAN_NB = BOOLEAN_NB

#         for example in split.train:
#             words = example.words
#             nb.addExample(example.klass, words)

#     return nb

def train(FILTER_STOP_WORDS, BOOLEAN_NB):
  nb = NaiveBayes()
  splits = nb.crossValidationSplits('data/imdb1')
  avgAccuracy = 0.0
  fold = 0
  for split in splits:
    classifier = NaiveBayes()
    classifier.FILTER_STOP_WORDS = FILTER_STOP_WORDS
    classifier.BOOLEAN_NB = BOOLEAN_NB
    accuracy = 0.0
    for example in split.train:
      words = example.words
      classifier.addExample(example.klass, words)
      nb.addExample(example.klass, words)

    for example in split.test:
      words = example.words
      guess = classifier.classify(words)
      if example.klass == guess:
        accuracy += 1.0

    accuracy = accuracy / len(split.test)
    avgAccuracy += accuracy
    print('[INFO]\tFold %d Accuracy: %f' % (fold, accuracy))
    fold += 1
  avgAccuracy = avgAccuracy / fold
  print('[INFO]\tAccuracy: %f' % avgAccuracy)
  return nb

#train our model, will take ~ 3 minutes
nb = train(FILTER_STOP_WORDS = True, BOOLEAN_NB = False)

# word =  " the untouchables  has some of the hippest , bravest heroes in any action film ."
# print(nb.classify(word.split()))